* Revalidate variance in all examples.
* Implement regularization as it appears dev accuracy is too low.
* Glorot is supposed to be not great with ReLU. Try randn*sqrt(2/n[l-1])
* Understand why PyTorch still differs from Numo implementation.
* Use Keras or Torch and continue next steps in recognition using convolutional layers, transfer & multitask learning (C3W2), data augmentation, skip connections, RNNs...
* Implement regularization (Regularization parameter, Dropout, Early stopping) - see C2W1 - Find a usecase when I overfit
* Add data augmentation.
* Find techniques that are efficient for hyper parameters tuning - See C2W3
* Add Recall as a metric - See C3W1
* Add OpenBLAS library location in the options
